{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df6eded-4456-406f-b5b9-bab9bc7c687a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/metavision_core_ml/preprocessing/viz.py:41: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _viz_events(events, img):\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from lava.magma.core.run_configs import Loihi2SimCfg, Loihi2HwCfg\n",
    "from lava.magma.core.run_conditions import RunSteps, RunContinuous\n",
    "from lava.magma.core.decorator import implements, requires, tag\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "from lava.magma.core.model.py.ports import PyOutPort, PyInPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "from lava.magma.core.process.ports.ports import OutPort, InPort\n",
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.resources import CPU\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.proc.io.sink import RingBuffer\n",
    "\n",
    "from lava.lib.peripherals.dvs.inivation import InivationCamera\n",
    "from lava.lib.peripherals.dvs.prophesee import PropheseeCamera\n",
    "from metavision_core.utils import get_sample\n",
    "from metavision_sdk_cv import TrailFilterAlgorithm, ActivityNoiseFilterAlgorithm\n",
    "from metavision_sdk_core import PolarityFilterAlgorithm\n",
    "\n",
    "from multiprocessing import Pipe\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import IPython\n",
    "\n",
    "\n",
    "from metavision_core.event_io import RawReader\n",
    "from lava.lib.peripherals.dvs.transform import Compose, MirrorHorizontally, MirrorVertically, MergePolarities, Downsample\n",
    "from metavision_ml.preprocessing import histo, histo_quantized\n",
    "from metavision_core.event_io import RawReader\n",
    "\n",
    "from lava.proc.lif.process import LIF, LogConfig\n",
    "from lava.proc.dense.process import Dense\n",
    "from lava.proc.sparse.process import Sparse\n",
    "import logging\n",
    "from lava.proc.dense.models import PyDenseModelBitAcc\n",
    "from lava.proc.lif.models import PyLifModelBitAcc\n",
    "from lava.proc.sparse.models import PySparseModelBitAcc\n",
    "\n",
    "from utils import VisSwipeProcess\n",
    "from scipy.sparse import csr_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602de9c0-4501-42b3-b604-589346b82b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_FILENAME_RAW = \"hand_swipe.dat\"\n",
    "# if the file doesn't exist, it will be downloaded from Prophesee's public sample server\n",
    "# get_sample(SEQUENCE_FILENAME_RAW)\n",
    "\n",
    "# reader = RawReader(SEQUENCE_FILENAME_RAW)\n",
    "# height, width = reader.get_size()\n",
    "# del reader\n",
    "width, height = (640, 480)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f09284e-4f27-4aa0-98a8-6a8edc66cdcd",
   "metadata": {},
   "source": [
    "## Swipe detector\n",
    "\n",
    "In the next section, we will create a simple hand gesture recognition model. For this purpose, we create a simple network in Lava in which we hand crafted the connectivity to detect general motion in the input stream.\n",
    "\n",
    "### Connectivity\n",
    "\n",
    "There are four population of LIF neurons detecting the directions 'up', 'down', 'left' and 'right'. Each population is recurrently connected with a shifted local kernel. For example the neurons in the up channel connects such that a neuron excites its neurons above. If the movement in the image is indeed upwards, there will be more events in the 'up' population compared to the others. This number of events in each population is used to predict the overall movement in the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b2cfc-af5f-4f2b-a0d7-26d338e5d991",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> UP</td>\n",
    "    <td> RIGHT </td>\n",
    "    <td> DOWN </td>\n",
    "    <td> LEFT </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td> <img src=\"imgs/swipe_kernel_right.png\" alt=\"Drawing\" style=\"height: 250px;\"/> </td>\n",
    "    <td> <img src=\"imgs/swipe_kernel_left.png\" alt=\"Drawing\" style=\"height: 250px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f295a395-155b-4504-985f-28c1fd92bdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Cam\n",
      "NUM NEURONS 12288\n",
      "Create FF weights\n",
      "Create left weights\n",
      "Create right weights\n",
      "Create out weights\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "transformations = Compose(\n",
    "    [\n",
    "        Downsample(factor=0.2),\n",
    "        MergePolarities(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Create Cam\")\n",
    "# Init Processes\n",
    "# frame_input = InivationCamera(device=\"\",\n",
    "#                               transformations=transformations,\n",
    "#                               sensor_shape=(height, width),\n",
    "#                               num_output_time_bins=1)\n",
    "\n",
    "frame_input = PropheseeCamera(filename=SEQUENCE_FILENAME_RAW,\n",
    "                              transformations=transformations,\n",
    "                              sensor_shape=(height, width),\n",
    "                              num_output_time_bins=1)\n",
    "\n",
    "num_neurons = np.prod(frame_input.s_out.shape)\n",
    "print(\"NUM NEURONS\", num_neurons)\n",
    "_, _, scaled_height, scaled_width = frame_input.s_out.shape\n",
    "flat_shape = (num_neurons, )\n",
    "num_out_neurons = 50\n",
    "\n",
    "w_ff = 255\n",
    "w_rec = 5\n",
    "w_o = 16\n",
    "kernel_size = 20\n",
    "\n",
    "vth = 600\n",
    "du = 2000\n",
    "dv = 2000\n",
    "\n",
    "\n",
    "print(\"Create FF weights\")\n",
    "\n",
    "ff_weights = csr_matrix(np.eye(num_neurons) * w_ff)\n",
    "\n",
    "print(\"Create left weights\")\n",
    "rec_weights_left = np.zeros((num_neurons, num_neurons)).reshape((scaled_height, scaled_width, scaled_height, scaled_width))\n",
    "for i in range(scaled_height):\n",
    "    for j in range(scaled_width):\n",
    "        rec_weights_left[i, j-kernel_size:j, i, j] = w_rec\n",
    "\n",
    "\n",
    "rec_weights_left = csr_matrix(rec_weights_left.reshape((num_neurons, num_neurons)))\n",
    "\n",
    "print(\"Create right weights\")\n",
    "rec_weights_right = np.zeros((num_neurons, num_neurons)).reshape((scaled_height, scaled_width, scaled_height, scaled_width))\n",
    "for i in range(scaled_height):\n",
    "    for j in range(scaled_width):\n",
    "        rec_weights_right[i, j+1:j+kernel_size+1, i, j] = w_rec\n",
    "\n",
    "rec_weights_right = csr_matrix(rec_weights_right.reshape((num_neurons, num_neurons)))\n",
    "\n",
    "print(\"Create out weights\")\n",
    "\n",
    "w_out_left = np.zeros((2*num_out_neurons, num_neurons))\n",
    "w_out_right = np.zeros((2*num_out_neurons, num_neurons))\n",
    "\n",
    "tmp = np.kron(np.eye(num_out_neurons, dtype=np.int32), np.array([w_o] * (num_neurons // num_out_neurons)))\n",
    "\n",
    "\n",
    "w_out_left[:num_out_neurons, :tmp.shape[1]] = tmp\n",
    "w_out_right[num_out_neurons:2*num_out_neurons, :tmp.shape[1]] = tmp\n",
    "\n",
    "w_out_left[:, 0] = 1 # bug fix\n",
    "w_out_right[:, 0] = 1 # bug fix\n",
    "\n",
    "w_out_left = csr_matrix(w_out_left)\n",
    "w_out_right = csr_matrix(w_out_right)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f2219f9-5dcb-4efa-869d-ed160672bcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create inp processes\n",
      "Create left processes\n",
      "Create right processes\n",
      "Create out processes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Create inp processes\")\n",
    "ff_inp = Sparse(weights=ff_weights, num_message_bits=8)\n",
    "lif_inp = LIF(shape=frame_input.shape,\n",
    "              du=4095,\n",
    "              dv=4095,\n",
    "              vth=1)\n",
    "\n",
    "print(\"Create left processes\")\n",
    "ff_left = Sparse(weights=ff_weights)\n",
    "rec_left = Sparse(weights=rec_weights_left)\n",
    "lif_left = LIF(shape=frame_input.shape,\n",
    "              du=du,\n",
    "              dv=dv,\n",
    "              vth=vth)\n",
    "\n",
    "print(\"Create right processes\")\n",
    "ff_right = Sparse(weights=ff_weights)\n",
    "rec_right = Sparse(weights=rec_weights_right)\n",
    "lif_right = LIF(shape=frame_input.shape,\n",
    "                du=du,\n",
    "                dv=dv,\n",
    "                vth=vth)\n",
    "\n",
    "print(\"Create out processes\")\n",
    "\n",
    "sparse_out_left = Sparse(weights=w_out_left)\n",
    "sparse_out_right = Sparse(weights=w_out_right)\n",
    "\n",
    "sparse_out_left_inv = Sparse(weights=-w_out_right)\n",
    "sparse_out_right_inv = Sparse(weights=-w_out_left)\n",
    "\n",
    "out_lif = LIF(shape=(2*num_out_neurons, ), \n",
    "              du=du,\n",
    "              dv=dv,\n",
    "              vth=vth)\n",
    "\n",
    "\n",
    "recv = VisSwipeProcess(shape=frame_input.s_out.shape,\n",
    "                       direction_shape=(2*num_out_neurons, ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ae5d7f7-3a6e-41a3-83cd-76f6d411f652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connect\n"
     ]
    }
   ],
   "source": [
    "print(\"Connect\")\n",
    "# Connect\n",
    "\n",
    "frame_input.s_out.flatten().connect(ff_inp.s_in)\n",
    "ff_inp.a_out.reshape(lif_inp.a_in.shape).connect(lif_inp.a_in)\n",
    "\n",
    "lif_inp.s_out.flatten().connect(ff_left.s_in)\n",
    "ff_left.a_out.reshape(lif_left.a_in.shape).connect(lif_left.a_in)\n",
    "lif_left.s_out.flatten().connect(rec_left.s_in)\n",
    "rec_left.a_out.reshape(lif_left.a_in.shape).connect(lif_left.a_in)\n",
    "lif_left.s_out.flatten().connect(sparse_out_left.s_in)\n",
    "sparse_out_left.a_out.connect(out_lif.a_in)\n",
    "lif_left.s_out.flatten().connect(sparse_out_left_inv.s_in)\n",
    "sparse_out_left_inv.a_out.connect(out_lif.a_in)\n",
    "\n",
    "lif_inp.s_out.flatten().connect(ff_right.s_in)\n",
    "ff_right.a_out.reshape(lif_right.a_in.shape).connect(lif_right.a_in)\n",
    "lif_right.s_out.flatten().connect(rec_right.s_in)\n",
    "rec_right.a_out.reshape(lif_right.a_in.shape).connect(lif_right.a_in)\n",
    "lif_right.s_out.flatten().connect(sparse_out_right.s_in)\n",
    "sparse_out_right.a_out.connect(out_lif.a_in)\n",
    "lif_right.s_out.flatten().connect(sparse_out_right_inv.s_in)\n",
    "sparse_out_right_inv.a_out.connect(out_lif.a_in)\n",
    "\n",
    "out_lif.s_out.connect(recv.direction_in)\n",
    "\n",
    "frame_input.s_out.connect(recv.frame_in)\n",
    "lif_left.s_out.connect(recv.left_in)\n",
    "lif_right.s_out.connect(recv.right_in)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e456b29-9503-4546-adc7-37c8d511dcf3",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"gifs/swipe.gif\" alt=\"Drawing\" style=\"height: 250px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbca89b-6f3e-463a-a9a0-cf34b23600f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run\n"
     ]
    }
   ],
   "source": [
    "print(\"Run\")\n",
    "# Run\n",
    "num_steps = 800\n",
    "run_cfg = Loihi2SimCfg(exception_proc_model_map={Dense: PyDenseModelBitAcc, Sparse: PySparseModelBitAcc, LIF: PyLifModelBitAcc})\n",
    "run_cnd = RunSteps(num_steps=num_steps)\n",
    "\n",
    "frame_input.run(condition=run_cnd, run_cfg=run_cfg)\n",
    "frame_input.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd7571-ce0c-4214-8c40-3e6d6d257f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a401fb25-91d3-415b-b9d0-c76e0b69514b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
