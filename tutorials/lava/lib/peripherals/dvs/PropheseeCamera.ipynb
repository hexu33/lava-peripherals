{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21d15919-bad4-4363-b458-520b30510ca5",
   "metadata": {},
   "source": [
    "# Prophesee Event Camera \n",
    "\n",
    "In this tutorial we demonstrate how to obtain data from a Prophesee camera and stream the events into Lava. We show the basic usage of the PropheseeCamera Process and how to apply filters and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df6eded-4456-406f-b5b9-bab9bc7c687a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/metavision_core_ml/preprocessing/viz.py:41: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _viz_events(events, img):\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from lava.magma.core.run_configs import Loihi2SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "\n",
    "from lava.lib.peripherals.dvs.prophesee import PropheseeCamera\n",
    "from metavision_core.utils import get_sample\n",
    "from metavision_sdk_cv import TrailFilterAlgorithm, ActivityNoiseFilterAlgorithm\n",
    "from metavision_core.event_io import RawReader\n",
    "from lava.lib.peripherals.dvs.transform import Compose, Downsample\n",
    "\n",
    "from utils import VisProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e456b29-9503-4546-adc7-37c8d511dcf3",
   "metadata": {},
   "source": [
    "\n",
    "## Download raw event recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602de9c0-4501-42b3-b604-589346b82b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_FILENAME_RAW = \"80_balls.raw\"\n",
    "# if the file doesn't exist, it will be downloaded from Prophesee's public sample server\n",
    "get_sample(SEQUENCE_FILENAME_RAW)\n",
    "\n",
    "reader = RawReader(SEQUENCE_FILENAME_RAW)\n",
    "height, width = reader.get_size()\n",
    "del reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e72821b-418a-451d-a52d-1e33f96faccb",
   "metadata": {},
   "source": [
    "## Basic usage\n",
    "\n",
    "Initialize PropheseeCamera using the path to a recording file if RAW format, in order to use a live camera, replace the path with an empty string (\"\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c3774-0132-4858-b10d-94c0bac212c0",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"gifs/basic.gif\" alt=\"Drawing\" style=\"height: 250px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce2d8f2-a440-4d4f-a86b-b0b62d3fbee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Init Processes\n",
    "frame_input = PropheseeCamera(device=SEQUENCE_FILENAME_RAW,\n",
    "                              sensor_shape=(height, width),\n",
    "                              num_output_time_bins=1)\n",
    "\n",
    "recv = VisProcess(shape=frame_input.s_out.shape)\n",
    "\n",
    "# Connect\n",
    "frame_input.s_out.connect(recv.s_in)\n",
    "\n",
    "# Run\n",
    "num_steps = 200\n",
    "run_cfg = Loihi2SimCfg()\n",
    "run_cnd = RunSteps(num_steps=num_steps)\n",
    "\n",
    "frame_input.run(condition=run_cnd, run_cfg=run_cfg)\n",
    "frame_input.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a80a0-3d5f-4317-9a95-14b121bbf1d5",
   "metadata": {},
   "source": [
    "## Apply filters\n",
    "\n",
    "As you see, the falling balls in the recording cause a trail of events. In many cases these trails are blurring the objects and are undesired. In order to reduce the trails, we can apply the TrailFilterAlgorithm from the metavision_sdk. See the metavision documentation for more filters and their usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9fc5fb-30d8-4cd4-bb0f-42b2fe0aa5ef",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"gifs/filters.gif\" alt=\"Drawing\" style=\"height: 250px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ef5962-56de-411c-ba02-2113163703d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [TrailFilterAlgorithm(width=width, height=height, threshold=100000),\n",
    "           ActivityNoiseFilterAlgorithm(width=width, height=height, threshold=1000),]\n",
    "\n",
    "\n",
    "# Init Processes\n",
    "frame_input = PropheseeCamera(device=SEQUENCE_FILENAME_RAW,\n",
    "                              filters=filters,\n",
    "                              sensor_shape=(height, width),\n",
    "                              num_output_time_bins=1)\n",
    "\n",
    "recv = VisProcess(shape=frame_input.s_out.shape)\n",
    "\n",
    "# Connect\n",
    "frame_input.s_out.connect(recv.s_in)\n",
    "\n",
    "# Run\n",
    "num_steps = 200\n",
    "run_cfg = Loihi2SimCfg()\n",
    "run_cnd = RunSteps(num_steps=num_steps)\n",
    "\n",
    "frame_input.run(condition=run_cnd, run_cfg=run_cfg)\n",
    "frame_input.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebade859-eaca-4b07-a6df-3ecf4136df62",
   "metadata": {},
   "source": [
    "## Apply transformations\n",
    "\n",
    "We provide numerous transformations to be applied to the event data. For example Downsampling, MergePolarities and Mirroring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e91714a-baa6-4dfb-aa62-af0932e017d7",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"gifs/transform.gif\" alt=\"Drawing\" style=\"height: 125px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c87662b-1fe1-4594-bcb0-2a30da9bf41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = Compose(\n",
    "    [\n",
    "        Downsample(factor=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Init Processes\n",
    "frame_input = PropheseeCamera(device=SEQUENCE_FILENAME_RAW,\n",
    "                              transformations=transformations,\n",
    "                              sensor_shape=(height, width),\n",
    "                              num_output_time_bins=1)\n",
    "\n",
    "recv = VisProcess(shape=frame_input.s_out.shape)\n",
    "\n",
    "# Connect\n",
    "frame_input.s_out.connect(recv.s_in)\n",
    "\n",
    "# Run\n",
    "num_steps = 200\n",
    "run_cfg = Loihi2SimCfg()\n",
    "run_cnd = RunSteps(num_steps=num_steps)\n",
    "\n",
    "frame_input.run(condition=run_cnd, run_cfg=run_cfg)\n",
    "frame_input.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66130c3c-8e25-46ae-8433-2c3a2853027b",
   "metadata": {},
   "source": [
    "## Custom transformation and manual output shape\n",
    "\n",
    "We also provide the option to use tonic transformations on the data. See the tonic documentation to see a complete list and usage. If you need to use custom transformation, the automatic shape determination would not work. In that case, you can specify the output shape manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdce5cd-4015-4330-a269-909e7f59d157",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"gifs/custom_trans.gif\" alt=\"Drawing\" style=\"height: 250px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fde088a-74c9-45dd-bee7-beca88caa39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_x_dim(events):\n",
    "    events['x'] += 500\n",
    "    return events\n",
    "    \n",
    "\n",
    "transformations = Compose(\n",
    "    [\n",
    "        expand_x_dim,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Init Processes\n",
    "frame_input = PropheseeCamera(device=SEQUENCE_FILENAME_RAW,\n",
    "                              transformations=transformations,\n",
    "                              sensor_shape=(height, width),\n",
    "                              num_output_time_bins=1,\n",
    "                              out_shape=(1, 2, height, width+500))\n",
    "\n",
    "recv = VisProcess(shape=frame_input.s_out.shape)\n",
    "\n",
    "# Connect\n",
    "frame_input.s_out.connect(recv.s_in)\n",
    "\n",
    "# Run\n",
    "num_steps = 200\n",
    "run_cfg = Loihi2SimCfg()\n",
    "run_cnd = RunSteps(num_steps=num_steps)\n",
    "\n",
    "frame_input.run(condition=run_cnd, run_cfg=run_cfg)\n",
    "frame_input.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
