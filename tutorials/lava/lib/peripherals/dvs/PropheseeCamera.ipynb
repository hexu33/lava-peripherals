{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21d15919-bad4-4363-b458-520b30510ca5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prophesee Event Camera \n",
    "\n",
    "In this tutorial we demonstrate how to stream event-based data from a Prophesee camera (or recording) into Lava. We show the basic usage of the `PropheseeCamera` Process and how to apply filters and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df6eded-4456-406f-b5b9-bab9bc7c687a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from lava.magma.core.run_configs import Loihi2SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "\n",
    "from lava.lib.peripherals.dvs.prophesee import PropheseeCamera\n",
    "\n",
    "from utils import EventVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e456b29-9503-4546-adc7-37c8d511dcf3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Download raw event recording\n",
    "\n",
    "Open the RAW event data file. If the file does not exist, it will be downloaded from Prophesee's public sample server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602de9c0-4501-42b3-b604-589346b82b19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import metavision_core as mv\n",
    "\n",
    "EVENT_RECORDING_FILENAME = \"80_balls.raw\"\n",
    "mv.utils.get_sample(EVENT_RECORDING_FILENAME)\n",
    "\n",
    "reader = mv.event_io.RawReader(EVENT_RECORDING_FILENAME)\n",
    "height, width = reader.get_size()\n",
    "del reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e72821b-418a-451d-a52d-1e33f96faccb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Basic usage\n",
    "\n",
    "The `PropheseeCamera` Process can be used to stream from a Prophesee camera or to stream from a recording. To stream from a recording, specify the file name and path in the `filename` parameter. To stream from a camera, do not specify the parameter or set it to an empty string (\"\").\n",
    "\n",
    "The output of the `PropheseeCamera` is an event histogram over all pixels, holding the number of events per pixel. The time span over which this histogram is generated can be specified with the optional `num_output_time_bins` parameter, which defaults to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c3774-0132-4858-b10d-94c0bac212c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"gifs/basic.gif\" alt=\"Drawing\" style=\"height: 250px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce2d8f2-a440-4d4f-a86b-b0b62d3fbee9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Processes\n",
    "camera = PropheseeCamera(filename=EVENT_RECORDING_FILENAME,\n",
    "                         sensor_shape=(height, width))\n",
    "\n",
    "event_visualizer = EventVisualizer(shape=camera.s_out.shape)\n",
    "\n",
    "# Connect\n",
    "camera.s_out.connect(event_visualizer.s_in)\n",
    "\n",
    "# Run\n",
    "num_steps = 200\n",
    "run_cfg = Loihi2SimCfg()\n",
    "run_cnd = RunSteps(num_steps=num_steps)\n",
    "\n",
    "camera.run(condition=run_cnd, run_cfg=run_cfg)\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a80a0-3d5f-4317-9a95-14b121bbf1d5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Apply filters\n",
    "\n",
    "The `PropheseeCamera` Process can preprocess event-based data using filters from the metavision_sdk. For instance, the falling balls in the recording cause a trail of events. Such trails often cause undesirable blurring of moving objects in the scene. To reduce such trails, apply the `TrailFilterAlgorithm` from the metavision_sdk. Refer to the metavision documentation for more filters and their usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9fc5fb-30d8-4cd4-bb0f-42b2fe0aa5ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"gifs/filters.gif\" alt=\"Drawing\" style=\"height: 250px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ef5962-56de-411c-ba02-2113163703d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from metavision_sdk_cv import TrailFilterAlgorithm, ActivityNoiseFilterAlgorithm\n",
    "\n",
    "\n",
    "filters = [TrailFilterAlgorithm(width=width, height=height, threshold=100000),\n",
    "           ActivityNoiseFilterAlgorithm(width=width, height=height, threshold=1000),]\n",
    "\n",
    "\n",
    "# Initialize Processes\n",
    "camera = PropheseeCamera(filename=EVENT_RECORDING_FILENAME,\n",
    "                         filters=filters,\n",
    "                         sensor_shape=(height, width))\n",
    "\n",
    "event_visualizer = EventVisualizer(shape=camera.s_out.shape)\n",
    "\n",
    "# Connect\n",
    "camera.s_out.connect(event_visualizer.s_in)\n",
    "\n",
    "# Run\n",
    "num_steps = 200\n",
    "run_cfg = Loihi2SimCfg()\n",
    "run_cnd = RunSteps(num_steps=num_steps)\n",
    "\n",
    "camera.run(condition=run_cnd, run_cfg=run_cfg)\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebade859-eaca-4b07-a6df-3ecf4136df62",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Apply transformations\n",
    "\n",
    "Lava-peripherals includes transformations that can be applied to the event data, for instance down-sampling, merging of polarities, and mirroring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e91714a-baa6-4dfb-aa62-af0932e017d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"gifs/transform.gif\" alt=\"Drawing\" style=\"height: 125px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c87662b-1fe1-4594-bcb0-2a30da9bf41a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from lava.lib.peripherals.dvs.transform import Compose, Downsample\n",
    "\n",
    "transformations = Compose(\n",
    "    [\n",
    "        Downsample(factor=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize Processes\n",
    "camera = PropheseeCamera(filename=EVENT_RECORDING_FILENAME,\n",
    "                              transformations=transformations,\n",
    "                              sensor_shape=(height, width),\n",
    "                              num_output_time_bins=1)\n",
    "\n",
    "event_visualizer = EventVisualizer(shape=camera.s_out.shape)\n",
    "\n",
    "# Connect\n",
    "camera.s_out.connect(event_visualizer.s_in)\n",
    "\n",
    "# Run\n",
    "num_steps = 200\n",
    "run_cfg = Loihi2SimCfg()\n",
    "run_cnd = RunSteps(num_steps=num_steps)\n",
    "\n",
    "camera.run(condition=run_cnd, run_cfg=run_cfg)\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66130c3c-8e25-46ae-8433-2c3a2853027b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Custom transformation and manual output shape\n",
    "\n",
    "The implementation of transformations is compatible with the transformations from both tonic and torchvision. Please refer to the tonic documentation to see a complete [list of available transformations and their usage](https://tonic.readthedocs.io/en/latest/auto_examples/index.html). If you need to use custom transformation, the output shape of the Process can not be determined automatically. In that case, you need to specify the output shape manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdce5cd-4015-4330-a269-909e7f59d157",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"gifs/custom_trans.gif\" alt=\"Drawing\" style=\"height: 250px;\"/> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fde088a-74c9-45dd-bee7-beca88caa39f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def expand_x_dim(events):\n",
    "    events['x'] += 500\n",
    "    return events\n",
    "    \n",
    "\n",
    "transformations = Compose(\n",
    "    [\n",
    "        expand_x_dim,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize Processes\n",
    "camera = PropheseeCamera(filename=EVENT_RECORDING_FILENAME,\n",
    "                         transformations=transformations,\n",
    "                         sensor_shape=(height, width),\n",
    "                         out_shape=(1, 2, height, width+500))\n",
    "\n",
    "event_visualizer = EventVisualizer(shape=camera.s_out.shape)\n",
    "\n",
    "# Connect\n",
    "camera.s_out.connect(event_visualizer.s_in)\n",
    "\n",
    "# Run\n",
    "num_steps = 200\n",
    "run_cfg = Loihi2SimCfg()\n",
    "run_cnd = RunSteps(num_steps=num_steps)\n",
    "\n",
    "camera.run(condition=run_cnd, run_cfg=run_cfg)\n",
    "camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}